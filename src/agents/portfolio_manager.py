from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
import json
import re
import os
from datetime import datetime
from src.utils.logging_config import setup_logger

from src.agents.state import AgentState, show_agent_reasoning, show_workflow_status
from src.tools.openrouter_config import get_chat_completion
from src.utils.api_utils import agent_endpoint, log_llm_interaction

# åˆå§‹åŒ– logger
logger = setup_logger('portfolio_management_agent')

##### Portfolio Management Agent #####

# Helper function to get the latest message by agent name


def get_latest_message_by_name(messages: list, name: str):
    for msg in reversed(messages):
        if msg.name == name:
            return msg
    logger.warning(
        f"Message from agent '{name}' not found in portfolio_management_agent.")
    # Return a dummy message object or raise an error, depending on desired handling
    # For now, returning a dummy message to avoid crashing, but content will be None.
    return HumanMessage(content=json.dumps({"signal": "error", "details": f"Message from {name} not found"}), name=name)


def parse_agent_message_content(content: str, agent_name: str = "unknown") -> dict:
    """è§£æ agent æ¶ˆæ¯å†…å®¹ï¼Œå¤„ç†æ ¼å¼ä¸ä¸€è‡´é—®é¢˜
    
    Args:
        content: æ¶ˆæ¯å†…å®¹ï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ–çº¯æ–‡æœ¬ï¼‰
        agent_name: agent åç§°ï¼Œç”¨äºæ—¥å¿—
        
    Returns:
        è§£æåçš„å­—å…¸ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›ç©ºå­—å…¸
    """
    if not content:
        return {}
    
    # å°è¯•è§£æä¸º JSON
    try:
        if isinstance(content, str):
            return json.loads(content)
        elif isinstance(content, dict):
            return content
        else:
            return {}
    except (json.JSONDecodeError, TypeError):
        # å¦‚æœä¸æ˜¯ JSONï¼Œè¿”å›åŒ…å«åŸå§‹å†…å®¹çš„å­—å…¸
        logger.debug(f"{agent_name} æ¶ˆæ¯ä¸æ˜¯ JSON æ ¼å¼ï¼Œè¿”å›åŸå§‹å†…å®¹")
        return {"raw_content": content}


def normalize_confidence(confidence_value) -> float:
    """æ ‡å‡†åŒ– confidence å€¼ä¸º 0-1 ä¹‹é—´çš„æµ®ç‚¹æ•°
    
    å¤„ç†ä¸åŒæ ¼å¼ï¼š
    - å­—ç¬¦ä¸² "75%" -> 0.75
    - å­—ç¬¦ä¸² "0.75" -> 0.75
    - æ•°å­— 0.75 -> 0.75
    - æ•°å­— 75 -> 0.75 (å‡è®¾æ˜¯ç™¾åˆ†æ¯”)
    
    Args:
        confidence_value: åŸå§‹ confidence å€¼
        
    Returns:
        æ ‡å‡†åŒ–åçš„æµ®ç‚¹æ•° (0-1)
    """
    if confidence_value is None:
        return 0.0
    
    if isinstance(confidence_value, (int, float)):
        # å¦‚æœæ˜¯æ•°å­—ï¼Œæ£€æŸ¥æ˜¯å¦å¤§äº1ï¼ˆå¯èƒ½æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼‰
        if confidence_value > 1.0:
            return confidence_value / 100.0
        return float(confidence_value)
    
    if isinstance(confidence_value, str):
        # ç§»é™¤ç©ºæ ¼å’Œç™¾åˆ†å·
        cleaned = confidence_value.strip().replace('%', '')
        try:
            value = float(cleaned)
            # å¦‚æœå¤§äº1ï¼Œå‡è®¾æ˜¯ç™¾åˆ†æ¯”å½¢å¼
            if value > 1.0:
                return value / 100.0
            return value
        except ValueError:
            logger.warning(f"æ— æ³•è§£æ confidence å€¼: {confidence_value}")
            return 0.0
    
    return 0.0


def parse_llm_json_response(response: str) -> dict:
    """è§£æ LLM è¿”å›çš„ JSON å“åº”ï¼Œå¤„ç† markdown ä»£ç å—å’Œé¢å¤–æ–‡æœ¬
    
    Args:
        response: LLM è¿”å›çš„åŸå§‹å“åº”å­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„ JSON å­—å…¸
        
    Raises:
        json.JSONDecodeError: å¦‚æœæ— æ³•è§£æä¸ºæœ‰æ•ˆçš„ JSON
    """
    if not response:
        raise json.JSONDecodeError("Empty response", response, 0)
    
    # æ¸…ç†å“åº”
    cleaned_response = response.strip()
    
    # æ–¹æ³•1: å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(cleaned_response)
    except json.JSONDecodeError:
        pass
    
    # æ–¹æ³•2: å°è¯•æå– markdown ä»£ç å—ä¸­çš„ JSON
    # åŒ¹é… ```json ... ``` æˆ– ``` ... ```
    json_block_patterns = [
        r'```json\s*(.*?)\s*```',  # ```json ... ```
        r'```\s*(.*?)\s*```',       # ``` ... ```
    ]
    
    for pattern in json_block_patterns:
        match = re.search(pattern, cleaned_response, re.DOTALL)
        if match:
            try:
                json_str = match.group(1).strip()
                return json.loads(json_str)
            except json.JSONDecodeError:
                continue
    
    # æ–¹æ³•3: å°è¯•æå–ç¬¬ä¸€ä¸ª { ... } ä¹‹é—´çš„å†…å®¹
    json_start = cleaned_response.find('{')
    if json_start >= 0:
        json_end = cleaned_response.rfind('}')
        if json_end > json_start:
            json_str = cleaned_response[json_start:json_end + 1]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                pass
    
    # æ–¹æ³•4: å°è¯•æå–ç¬¬ä¸€ä¸ª [ ... ] ä¹‹é—´çš„å†…å®¹ï¼ˆå¦‚æœæ˜¯æ•°ç»„æ ¼å¼ï¼‰
    array_start = cleaned_response.find('[')
    if array_start >= 0:
        array_end = cleaned_response.rfind(']')
        if array_end > array_start:
            json_str = cleaned_response[array_start:array_end + 1]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                pass
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
    raise json.JSONDecodeError(
        f"æ— æ³•è§£æ JSONã€‚å“åº”å‰200å­—ç¬¦: {cleaned_response[:200]}",
        cleaned_response,
        0
    )


@agent_endpoint("portfolio_management", "è´Ÿè´£æŠ•èµ„ç»„åˆç®¡ç†å’Œæœ€ç»ˆäº¤æ˜“å†³ç­–")
def portfolio_management_agent(state: AgentState):
    """Responsible for portfolio management"""
    agent_name = "portfolio_management_agent"
    logger.info(f"\n--- DEBUG: {agent_name} START ---")
    logger.info(f"ğŸ” DEBUG: æ”¶åˆ°çš„æ¶ˆæ¯åˆ—è¡¨: {[msg.name for msg in state['messages']]}")
    logger.info(f"ğŸ” DEBUG: æ¶ˆæ¯æ•°é‡: {len(state['messages'])}")

    # Log raw incoming messages
    # logger.info(
    # f"--- DEBUG: {agent_name} RAW INCOMING messages: {[msg.name for msg in state['messages']]} ---")
    # for i, msg in enumerate(state['messages']):
    #     logger.info(
    #         f"  DEBUG RAW MSG {i}: name='{msg.name}', content_preview='{str(msg.content)[:100]}...'")

    # Clean and unique messages by agent name, taking the latest if duplicates exist
    # This is crucial because this agent is a sink for multiple paths.
    unique_incoming_messages = {}
    for msg in state["messages"]:
        # Keep overriding with later messages to get the latest by name
        unique_incoming_messages[msg.name] = msg

    cleaned_messages_for_processing = list(unique_incoming_messages.values())
    # logger.info(
    # f"--- DEBUG: {agent_name} CLEANED messages for processing: {[msg.name for msg in cleaned_messages_for_processing]} ---")

    show_workflow_status(f"{agent_name}: --- Executing Portfolio Manager ---")
    show_reasoning_flag = state["metadata"]["show_reasoning"]
    portfolio = state["data"]["portfolio"]

    # ä¿æŠ¤æ£€æŸ¥ï¼šç¡®ä¿å…³é”®æ¶ˆæ¯å­˜åœ¨
    # å¦‚æœç¼ºå°‘ macro_analyst_agent æˆ– risk_management_agentï¼Œè¯´æ˜å·¥ä½œæµæ‰§è¡Œé¡ºåºæœ‰é—®é¢˜
    # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæå‰è¿”å›ï¼Œä¸æ‰§è¡Œä¸»è¦é€»è¾‘ï¼Œé¿å…é‡å¤æ‰“å°æŠ¥å‘Š
    required_agents = ["macro_analyst_agent", "risk_management_agent"]
    missing_agents = [agent for agent in required_agents 
                     if not any(msg.name == agent for msg in cleaned_messages_for_processing)]
    
    if missing_agents:
        logger.warning(f"âš ï¸ ç¼ºå°‘å…³é”®æ¶ˆæ¯: {missing_agents}ï¼Œportfolio_management_agent å¯èƒ½è¢«è¿‡æ—©è§¦å‘ï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
        logger.warning(f"å½“å‰æ¶ˆæ¯åˆ—è¡¨: {[msg.name for msg in cleaned_messages_for_processing]}")
        # æå‰è¿”å›ï¼Œä¸æ‰§è¡Œä¸»è¦é€»è¾‘ï¼Œé¿å…é‡å¤æ‰“å°æŠ¥å‘Š
        # è¿”å›å½“å‰çŠ¶æ€ï¼Œç­‰å¾…æ‰€æœ‰è¾“å…¥éƒ½å‡†å¤‡å¥½
        return {
            "messages": state["messages"],
            "data": state["data"],
            "metadata": state["metadata"]
        }

    # Get messages from other agents using the cleaned list
    technical_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "technical_analyst_agent")
    fundamentals_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "fundamentals_agent")
    sentiment_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "sentiment_agent")
    valuation_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "valuation_agent")
    risk_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "risk_management_agent")
    tool_based_macro_message = get_latest_message_by_name(
        cleaned_messages_for_processing, "macro_analyst_agent")  # This is the main analysis path output

    # Extract and parse content from messages, handling format inconsistencies
    technical_data = parse_agent_message_content(
        technical_message.content if technical_message else None, "technical_analyst_agent")
    fundamentals_data = parse_agent_message_content(
        fundamentals_message.content if fundamentals_message else None, "fundamentals_agent")
    sentiment_data = parse_agent_message_content(
        sentiment_message.content if sentiment_message else None, "sentiment_agent")
    valuation_data = parse_agent_message_content(
        valuation_message.content if valuation_message else None, "valuation_agent")
    risk_data = parse_agent_message_content(
        risk_message.content if risk_message else None, "risk_management_agent")
    tool_based_macro_data = parse_agent_message_content(
        tool_based_macro_message.content if tool_based_macro_message else None, "macro_analyst_agent")
    
    # æ ‡å‡†åŒ– confidence å€¼å¹¶é‡æ–°åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼ˆç”¨äº LLM promptï¼‰
    # åŒæ—¶ä¿ç•™åŸå§‹æ•°æ®ç”¨äºåç»­å¤„ç†
    # Technical agent æœ‰å¤æ‚çš„ç»“æ„ï¼Œä¿ç•™ strategy_signals
    technical_content_data = {
        "signal": technical_data.get("signal", "error"),
        "confidence": normalize_confidence(technical_data.get("confidence", 0.0)),
    }
    if "strategy_signals" in technical_data:
        technical_content_data["strategy_signals"] = technical_data["strategy_signals"]
    if "reasoning" in technical_data:
        technical_content_data["reasoning"] = technical_data["reasoning"]
    technical_content = json.dumps(technical_content_data)
    fundamentals_content = json.dumps({
        "signal": fundamentals_data.get("signal", "error"),
        "confidence": normalize_confidence(fundamentals_data.get("confidence", 0.0)),
        "details": fundamentals_data.get("details", "Fundamentals message missing" if not fundamentals_data else "Available")
    })
    sentiment_content = json.dumps({
        "signal": sentiment_data.get("signal", "error"),
        "confidence": normalize_confidence(sentiment_data.get("confidence", 0.0)),
        "details": sentiment_data.get("details", "Sentiment message missing" if not sentiment_data else "Available")
    })
    valuation_content = json.dumps({
        "signal": valuation_data.get("signal", "error"),
        "confidence": normalize_confidence(valuation_data.get("confidence", 0.0)),
        "details": valuation_data.get("details", "Valuation message missing" if not valuation_data else "Available")
    })
    risk_content = json.dumps({
        "signal": risk_data.get("trading_action", "error"),
        "max_position_size": risk_data.get("max_position_size", 0),
        "risk_score": risk_data.get("risk_score", 0),
        "details": risk_data.get("details", "Risk message missing" if not risk_data else "Available")
    })
    tool_based_macro_content = json.dumps({
        "signal": tool_based_macro_data.get("impact_on_stock", "error"),
        "macro_environment": tool_based_macro_data.get("macro_environment", "neutral"),
        "details": tool_based_macro_data.get("details", "Tool-based Macro message missing" if not tool_based_macro_data else "Available")
    })

    # Market-wide news summary from macro_news_agent (already correctly fetched from state["data"])
    market_wide_news_summary_content = state["data"].get(
        "macro_news_analysis_result", "å¤§ç›˜å®è§‚æ–°é—»åˆ†æä¸å¯ç”¨æˆ–æœªæä¾›ã€‚")
    # Optional: also try to get the message object for consistency in agent_signals, though data field is primary source
    macro_news_agent_message_obj = get_latest_message_by_name(
        cleaned_messages_for_processing, "macro_news_agent")

    system_message_content = """You are a portfolio manager making final trading decisions.
            Your job is to make a trading decision based on the team's analysis while strictly adhering
            to risk management constraints.

            RISK MANAGEMENT CONSTRAINTS:
            - You MUST NOT exceed the max_position_size specified by the risk manager
            - You MUST follow the trading_action (buy/sell/hold) recommended by risk management
            - These are hard constraints that cannot be overridden by other signals

            When weighing the different signals for direction and timing:
            1. Valuation Analysis (30% weight)
            2. Fundamental Analysis (25% weight)
            3. Technical Analysis (20% weight)
            4. Macro Analysis (15% weight) - This encompasses TWO inputs:
               a) General Macro Environment (from Macro Analyst Agent, tool-based)
               b) Daily Market-Wide News Summary (from Macro News Agent)
               Both provide context for external risks and opportunities.
            5. Sentiment Analysis (10% weight)

            The decision process should be:
            1. First check risk management constraints
            2. Then evaluate valuation signal
            3. Then evaluate fundamentals signal
            4. Consider BOTH the General Macro Environment AND the Daily Market-Wide News Summary.
            5. Use technical analysis for timing
            6. Consider sentiment for final adjustment

            Provide the following in your output JSON:
            - "action": "buy" | "sell" | "hold",
            - "quantity": <positive integer>
            - "confidence": <float between 0 and 1>
            - "agent_signals": <list of agent signals including agent name, signal (bullish | bearish | neutral), and their confidence>.
              IMPORTANT: Your 'agent_signals' list MUST include entries for:
                - "technical_analysis"
                - "fundamental_analysis"
                - "sentiment_analysis"
                - "valuation_analysis"
                - "risk_management"
                - "selected_stock_macro_analysis" (representing the tool-based macro input from macro_analyst_agent)
                - "market_wide_news_summary(æ²ªæ·±300æŒ‡æ•°)" (representing the daily news summary input from macro_news_agent - provide a brief signal like bullish/bearish/neutral for the news summary itself, or state if it was primarily factored into overall reasoning with confidence reflecting its impact)
            - "reasoning": <concise explanation of the decision including how you weighted ALL signals, including both macro inputs>

            Trading Rules:
            - Never exceed risk management position limits
            - Only buy if you have available cash
            - Only sell if you have shares to sell
            - Quantity must be â‰¤ current position for sells
            - Quantity must be â‰¤ max_position_size from risk management"""
    system_message = {
        "role": "system",
        "content": system_message_content
    }

    user_message_content = f"""Based on the team's analysis below, make your trading decision.

            Technical Analysis Signal: {technical_content}
            Fundamental Analysis Signal: {fundamentals_content}
            Sentiment Analysis Signal: {sentiment_content}
            Valuation Analysis Signal: {valuation_content}
            Risk Management Signal: {risk_content}
            General Macro Analysis (from Macro Analyst Agent): {tool_based_macro_content}
            Daily Market-Wide News Summary (from Macro News Agent):
            {market_wide_news_summary_content}

            Current Portfolio:
            Cash: {portfolio['cash']:.2f}
            Current Position: {portfolio['stock']} shares

            Output JSON only. Ensure 'agent_signals' includes all required agents as per system prompt."""
    user_message = {
        "role": "user",
        "content": user_message_content
    }

    show_agent_reasoning(
        agent_name, f"Preparing LLM. User msg includes: TA, FA, Sent, Val, Risk, GeneralMacro, MarketNews.")

    llm_interaction_messages = [system_message, user_message]
    llm_response_content = get_chat_completion(llm_interaction_messages)

    current_metadata = state["metadata"]
    current_metadata["current_agent_name"] = agent_name

    def get_llm_result_for_logging_wrapper():
        return llm_response_content
    log_llm_interaction(state)(get_llm_result_for_logging_wrapper)()

    if llm_response_content is None:
        show_agent_reasoning(
            agent_name, "LLM call failed. Using default conservative decision.")
        # Ensure the dummy response matches the expected structure for agent_signals
        llm_response_content = json.dumps({
            "action": "hold",
            "quantity": 0,
            "confidence": 0.7,
            "agent_signals": [
                {"agent_name": "technical_analysis",
                    "signal": "neutral", "confidence": 0.0},
                {"agent_name": "fundamental_analysis",
                    "signal": "neutral", "confidence": 0.0},
                {"agent_name": "sentiment_analysis",
                    "signal": "neutral", "confidence": 0.0},
                {"agent_name": "valuation_analysis",
                    "signal": "neutral", "confidence": 0.0},
                {"agent_name": "risk_management",
                    "signal": "hold", "confidence": 1.0},
                {"agent_name": "macro_analyst_agent",
                    "signal": "neutral", "confidence": 0.0},
                {"agent_name": "macro_news_agent",
                    "signal": "unavailable_or_llm_error", "confidence": 0.0}
            ],
            "reasoning": "LLM API error. Defaulting to conservative hold based on risk management."
        })

    final_decision_message = HumanMessage(
        content=llm_response_content,
        name=agent_name,
    )

    if show_reasoning_flag:
        show_agent_reasoning(
            agent_name, f"Final LLM decision JSON: {llm_response_content}")

    agent_decision_details_value = {}
    formatted_report = None
    try:
        # ä½¿ç”¨æ”¹è¿›çš„ JSON è§£æå‡½æ•°
        decision_json = parse_llm_json_response(llm_response_content)
        action = decision_json.get("action", "hold")
        quantity = decision_json.get("quantity", 0)
        confidence = decision_json.get("confidence", 0.0)
        agent_signals = decision_json.get("agent_signals", [])
        reasoning = decision_json.get("reasoning", "")
        
        agent_decision_details_value = {
            "action": action,
            "quantity": quantity,
            "confidence": confidence,
            "reasoning_snippet": reasoning[:150] + "..." if reasoning else ""
        }
        
        # æ ¼å¼åŒ–å¹¶æ‰“å°æŠ•èµ„åˆ†ææŠ¥å‘Š
        try:
            # è®°å½• agent_signals çš„ç»“æ„ä»¥ä¾¿è°ƒè¯•
            logger.debug(f"agent_signals ç±»å‹: {type(agent_signals)}, é•¿åº¦: {len(agent_signals) if isinstance(agent_signals, list) else 'N/A'}")
            if isinstance(agent_signals, list) and len(agent_signals) > 0:
                logger.debug(f"ç¬¬ä¸€ä¸ª signal çš„ç±»å‹: {type(agent_signals[0])}, å†…å®¹: {agent_signals[0]}")
            
            # ä¼ é€’åŸå§‹ agent æ•°æ®ä»¥è·å–è¯¦ç»†ä¿¡æ¯
            formatted_report = format_decision(
                action=action,
                quantity=quantity,
                confidence=confidence,
                agent_signals=agent_signals,
                reasoning=reasoning,
                market_wide_news_summary=market_wide_news_summary_content,
                # ä¼ é€’åŸå§‹ agent æ•°æ®ä»¥è·å–è¯¦ç»†ä¿¡æ¯
                raw_agent_data={
                    "fundamentals": fundamentals_data,
                    "valuation": valuation_data,
                    "technical": technical_data,
                    "sentiment": sentiment_data,
                    "risk": risk_data,
                    "macro_analyst": tool_based_macro_data
                }
            )
            
            # æ‰“å°æŠ•èµ„åˆ†ææŠ¥å‘Šï¼ˆåªæ‰“å°ä¸€æ¬¡ï¼‰
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰“å°è¿‡æŠ¥å‘Šï¼ˆé€šè¿‡æ£€æŸ¥ metadata ä¸­çš„æ ‡å¿—ï¼‰
            report_already_printed = state["metadata"].get("portfolio_report_printed", False)
            
            if formatted_report and "åˆ†ææŠ¥å‘Š" in formatted_report and not report_already_printed:
                logger.info("\n" + "="*60)
                logger.info("ğŸ“Š æŠ•èµ„åˆ†ææŠ¥å‘Š")
                logger.info("="*60)
                logger.info(formatted_report["åˆ†ææŠ¥å‘Š"])
                logger.info("="*60 + "\n")
                
                # å¦‚æœå¯ç”¨äº† show_reasoningï¼Œä¹Ÿé€šè¿‡ show_agent_reasoning æ˜¾ç¤º
                if show_reasoning_flag:
                    show_agent_reasoning(agent_name, formatted_report["åˆ†ææŠ¥å‘Š"])
                
                # ä¿å­˜ä¸º markdown æ–‡ä»¶
                try:
                    ticker = state["data"].get("ticker", "UNKNOWN")
                    current_date = datetime.now().strftime("%Y%m%d")
                    report_filename = f"{ticker}_{current_date}.md"
                    
                    # åˆ›å»º reports ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼šä» src/agents/portfolio_manager.py å‘ä¸Šä¸‰çº§
                    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                    reports_dir = os.path.join(project_root, "reports")
                    os.makedirs(reports_dir, exist_ok=True)
                    
                    report_filepath = os.path.join(reports_dir, report_filename)
                    
                    # æ„å»ºå®Œæ•´çš„ markdown æŠ¥å‘Š
                    # å°†æ–‡æœ¬æŠ¥å‘Šè½¬æ¢ä¸º markdown æ ¼å¼ï¼ˆå¤„ç†ç­‰å·åˆ†éš”çº¿ï¼‰
                    report_text = formatted_report["åˆ†ææŠ¥å‘Š"]
                    # å°†ç­‰å·åˆ†éš”çº¿è½¬æ¢ä¸º markdown åˆ†éš”çº¿
                    report_text = re.sub(r'={60,}', '---', report_text)
                    # å°†æ–‡æœ¬ä¸­çš„æ ‡é¢˜è½¬æ¢ä¸º markdown æ ‡é¢˜
                    report_text = re.sub(r'^(\d+[\.ã€])\s*(.+)$', r'## \2', report_text, flags=re.MULTILINE)
                    
                    # å¦‚æœå¯ç”¨äº† show_reasoningï¼Œæ”¶é›†æ‰€æœ‰ agent çš„è¯¦ç»†æ¨ç†ä¿¡æ¯
                    detailed_reasoning_section = ""
                    if show_reasoning_flag:
                        detailed_reasoning_parts = []
                        
                        # Agent åç§°æ˜ å°„ï¼ˆä¸­æ–‡æ˜¾ç¤ºåç§°ï¼‰
                        agent_name_map = {
                            "technical_analyst_agent": "æŠ€æœ¯åˆ†æå¸ˆ",
                            "fundamentals_agent": "åŸºæœ¬é¢åˆ†æå¸ˆ",
                            "sentiment_agent": "æƒ…ç»ªåˆ†æå¸ˆ",
                            "valuation_agent": "ä¼°å€¼åˆ†æå¸ˆ",
                            "risk_management_agent": "é£é™©ç®¡ç†ä¸“å®¶",
                            "macro_analyst_agent": "å®è§‚åˆ†æå¸ˆ",
                            "macro_news_agent": "å®è§‚æ–°é—»åˆ†æå¸ˆ",
                            "researcher_bull_agent": "çœ‹å¤šç ”ç©¶å‘˜",
                            "researcher_bear_agent": "çœ‹ç©ºç ”ç©¶å‘˜",
                            "debate_room_agent": "è¾©è®ºå®¤"
                        }
                        
                        # æ”¶é›†å„ä¸ª agent çš„è¯¦ç»†æ•°æ®
                        for msg in cleaned_messages_for_processing:
                            agent_name = msg.name
                            if agent_name and agent_name in agent_name_map:
                                try:
                                    # è§£ææ¶ˆæ¯å†…å®¹
                                    agent_data = parse_agent_message_content(msg.content, agent_name)
                                    if agent_data:
                                        display_name = agent_name_map.get(agent_name, agent_name)
                                        detailed_reasoning_parts.append(f"""
### {display_name} ({agent_name})

```json
{json.dumps(agent_data, ensure_ascii=False, indent=2)}
```
""")
                                except Exception as e:
                                    logger.debug(f"è§£æ {agent_name} çš„è¯¦ç»†æ¨ç†ä¿¡æ¯æ—¶å‡ºé”™: {e}")
                        
                        if detailed_reasoning_parts:
                            detailed_reasoning_section = f"""

---

## è¯¦ç»†æ¨ç†ä¿¡æ¯

> ä»¥ä¸‹å†…å®¹åŒ…å«å„ä¸ªåˆ†æ Agent çš„å®Œæ•´æ¨ç†è¿‡ç¨‹å’Œè¯¦ç»†æ•°æ®ï¼Œä»…åœ¨å¯ç”¨ `--show-reasoning` å‚æ•°æ—¶æ˜¾ç¤ºã€‚

{''.join(detailed_reasoning_parts)}
"""
                    
                    markdown_content = f"""# æŠ•èµ„åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯

- **è‚¡ç¥¨ä»£ç **: {ticker}
- **åˆ†ææ—¥æœŸ**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}
- **æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

{report_text}

---

## æœ€ç»ˆå†³ç­–

- **æ“ä½œå»ºè®®**: {'ä¹°å…¥' if action == 'buy' else 'å–å‡º' if action == 'sell' else 'æŒæœ‰'}
- **äº¤æ˜“æ•°é‡**: {quantity} è‚¡
- **å†³ç­–ç½®ä¿¡åº¦**: {confidence*100:.1f}%

## åŸå§‹å†³ç­–æ•°æ®

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹åŸå§‹ JSON æ•°æ®</summary>

```json
{json.dumps(decision_json, ensure_ascii=False, indent=2)}
```

</details>
{detailed_reasoning_section}
---

*æœ¬æŠ¥å‘Šç”± AI æŠ•èµ„åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚*
"""
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(report_filepath, 'w', encoding='utf-8') as f:
                        f.write(markdown_content)
                    
                    logger.info(f"âœ… æŠ•èµ„åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filepath}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜ markdown æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
                    logger.exception("è¯¦ç»†é”™è¯¯:")
                
                # æ ‡è®°æŠ¥å‘Šå·²æ‰“å°ï¼Œé¿å…é‡å¤æ‰“å°
                state["metadata"]["portfolio_report_printed"] = True
            elif report_already_printed:
                logger.debug("æŠ•èµ„åˆ†ææŠ¥å‘Šå·²æ‰“å°ï¼Œè·³è¿‡é‡å¤æ‰“å°")
        except Exception as e:
            logger.warning(f"æ ¼å¼åŒ–æŠ•èµ„åˆ†ææŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯:")
            
    except json.JSONDecodeError as e:
        agent_decision_details_value = {
            "error": "Failed to parse LLM decision JSON from portfolio manager",
            "raw_response_snippet": llm_response_content[:500] + "..." if len(llm_response_content) > 500 else llm_response_content
        }
        logger.error(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSON: {str(e)}")
        logger.error(f"LLM åŸå§‹å“åº”ï¼ˆå‰500å­—ç¬¦ï¼‰: {llm_response_content[:500]}")
        logger.exception("JSON è§£æé”™è¯¯è¯¦æƒ…:")

    show_workflow_status(f"{agent_name}: --- Portfolio Manager Completed ---")
    logger.info(f"ğŸ DEBUG: {agent_name} æ‰§è¡Œå®Œæˆï¼Œå‡†å¤‡è¿”å›ç»“æœ")
    logger.info(f"ğŸ” DEBUG: è¿”å›çš„æ¶ˆæ¯æ•°é‡: {len(cleaned_messages_for_processing) + 1}")

    # The portfolio_management_agent is a terminal or near-terminal node in terms of new message generation for the main state.
    # It should return its own decision, and an updated state["messages"] that includes its decision.
    # As it's aæ±‡èšç‚¹, it should ideally start with a cleaned list of messages from its inputs.
    # The cleaned_messages_for_processing already did this. We append its new message to this cleaned list.

    # If we strictly want to follow the pattern of `state["messages"] + [new_message]` for all non-leaf nodes,
    # then the `cleaned_messages_for_processing` should become the new `state["messages"]` for this node's context.
    # However, for simplicity and robustness, let's assume its output `messages` should just be its own message added to the cleaned input it processed.

    final_messages_output = cleaned_messages_for_processing + [final_decision_message]
    # Alternative if we want to be super strict about adding to the raw incoming state["messages"]:
    # final_messages_output = state["messages"] + [final_decision_message]
    # But this ^ is prone to the duplication we are trying to solve if not careful.
    # The most robust is that portfolio_manager provides its clear output, and the graph handles accumulation if needed for further steps (none in this case as it's END).

    logger.info(
        f"ğŸ” DEBUG: {agent_name} RETURN messages: {[msg.name for msg in final_messages_output]}")
    logger.info(f"âœ… DEBUG: {agent_name} è¿”å›çŠ¶æ€å­—å…¸ï¼ŒåŒ…å« {len(final_messages_output)} æ¡æ¶ˆæ¯")

    return {
        "messages": final_messages_output,
        "data": state["data"],
        "metadata": {
            **state["metadata"],
            f"{agent_name}_decision_details": agent_decision_details_value,
            "agent_reasoning": llm_response_content
        }
    }


def format_decision(action: str, quantity: int, confidence: float, agent_signals: list, reasoning: str, market_wide_news_summary: str = "æœªæä¾›", raw_agent_data: dict = None) -> dict:
    """Format the trading decision into a standardized output format.
    Think in English but output analysis in Chinese."""
    
    # ç¡®ä¿ agent_signals æ˜¯åˆ—è¡¨ä¸”æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å­—å…¸
    if not isinstance(agent_signals, list):
        logger.warning(f"agent_signals ä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(agent_signals)}, å€¼: {agent_signals}")
        agent_signals = []
    
    # æ ‡å‡†åŒ– agent_signalsï¼šç»Ÿä¸€ä½¿ç”¨ 'agent_name' é”®
    # LLM å¯èƒ½è¿”å› 'agent' æˆ– 'agent_name'ï¼Œæˆ‘ä»¬ç»Ÿä¸€è½¬æ¢ä¸º 'agent_name'
    normalized_signals = []
    for s in agent_signals:
        if isinstance(s, dict):
            # åˆ›å»ºæ ‡å‡†åŒ–åçš„å­—å…¸
            normalized_s = dict(s)  # å¤åˆ¶åŸå­—å…¸
            
            # å¦‚æœåªæœ‰ 'agent' é”®ï¼Œæ·»åŠ  'agent_name' é”®
            if "agent" in normalized_s and "agent_name" not in normalized_s:
                normalized_s["agent_name"] = normalized_s["agent"]
            # å¦‚æœåªæœ‰ 'agent_name' é”®ä½†æ²¡æœ‰ 'agent'ï¼Œä¹Ÿæ·»åŠ  'agent' é”®ä»¥ä¿æŒå…¼å®¹
            elif "agent_name" in normalized_s and "agent" not in normalized_s:
                normalized_s["agent"] = normalized_s["agent_name"]
            
            # åªè¦æœ‰ 'agent' æˆ– 'agent_name' é”®ï¼Œå°±è®¤ä¸ºæ˜¯æœ‰æ•ˆä¿¡å·
            if "agent_name" in normalized_s or "agent" in normalized_s:
                normalized_signals.append(normalized_s)
    
    valid_signals = normalized_signals
    
    # è®°å½•æ ‡å‡†åŒ–ç»“æœ
    if len(valid_signals) < len(agent_signals):
        invalid_count = len(agent_signals) - len(valid_signals)
        logger.warning(f"æ ‡å‡†åŒ–åè¿‡æ»¤æ‰äº† {invalid_count} ä¸ªæ— æ•ˆçš„ agent_signalsï¼ˆæ€»å…± {len(agent_signals)} ä¸ªï¼‰")
        logger.debug(f"æ ‡å‡†åŒ–åçš„æœ‰æ•ˆä¿¡å·æ•°é‡: {len(valid_signals)}")
        for i, s in enumerate(valid_signals):
            logger.debug(f"æœ‰æ•ˆ signal[{i}]: agent_name={s.get('agent_name')}, signal={s.get('signal')}, confidence={s.get('confidence')}")

    # ä» agent_signals ä¸­è·å–ä¿¡å·å’Œç½®ä¿¡åº¦
    fundamental_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") == "fundamental_analysis"), None)
    valuation_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") == "valuation_analysis"), None)
    technical_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") == "technical_analysis"), None)
    sentiment_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") == "sentiment_analysis"), None)
    risk_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") == "risk_management"), None)
    
    # ä»åŸå§‹ agent æ•°æ®ä¸­è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    # ä¼˜å…ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå› ä¸ºå®ƒåŒ…å«å®Œæ•´çš„ reasoning ä¿¡æ¯
    fundamental_signal = raw_agent_data.get("fundamentals", {}) if raw_agent_data else {}
    if fundamental_signal_summary:
        # åˆå¹¶ä¿¡å·æ‘˜è¦ï¼ˆsignal, confidenceï¼‰åˆ°åŸå§‹æ•°æ®
        fundamental_signal = {**fundamental_signal, **fundamental_signal_summary}
    
    valuation_signal = raw_agent_data.get("valuation", {}) if raw_agent_data else {}
    if valuation_signal_summary:
        valuation_signal = {**valuation_signal, **valuation_signal_summary}
    
    technical_signal = raw_agent_data.get("technical", {}) if raw_agent_data else {}
    if technical_signal_summary:
        technical_signal = {**technical_signal, **technical_signal_summary}
    
    sentiment_signal = raw_agent_data.get("sentiment", {}) if raw_agent_data else {}
    if sentiment_signal_summary:
        sentiment_signal = {**sentiment_signal, **sentiment_signal_summary}
    
    risk_signal = raw_agent_data.get("risk", {}) if raw_agent_data else {}
    if risk_signal_summary:
        risk_signal = {**risk_signal, **risk_signal_summary}
    # Existing macro signal from macro_analyst_agent (tool-based)
    # LLM å¯èƒ½è¿”å› "selected_stock_macro_analysis" æˆ– "macro_analyst_agent"
    general_macro_signal_summary = next(
        (s for s in valid_signals if s.get("agent_name") in ["macro_analyst_agent", "selected_stock_macro_analysis"]), None)
    
    general_macro_signal = raw_agent_data.get("macro_analyst", {}) if raw_agent_data else {}
    if general_macro_signal_summary:
        general_macro_signal = {**general_macro_signal, **general_macro_signal_summary}
    # New market-wide news summary signal from macro_news_agent
    # LLM å¯èƒ½è¿”å› "market_wide_news_summary(æ²ªæ·±300æŒ‡æ•°)" æˆ– "macro_news_agent"
    market_wide_news_signal = next(
        (s for s in valid_signals if s.get("agent_name") and ("macro_news" in s.get("agent_name", "") or "market_wide" in s.get("agent_name", ""))), None)

    def signal_to_chinese(signal_data):
        if not signal_data:
            return "æ— æ•°æ®"
        if signal_data.get("signal") == "bullish":
            return "çœ‹å¤š"
        if signal_data.get("signal") == "bearish":
            return "çœ‹ç©º"
        return "ä¸­æ€§"

    detailed_analysis = f"""
====================================
          æŠ•èµ„åˆ†ææŠ¥å‘Š
====================================

ä¸€ã€ç­–ç•¥åˆ†æ

1. åŸºæœ¬é¢åˆ†æ (æƒé‡30%):
   ä¿¡å·: {signal_to_chinese(fundamental_signal)}
   ç½®ä¿¡åº¦: {((fundamental_signal or {}).get('confidence', 0.0) * 100):.0f}%
   è¦ç‚¹:
   - ç›ˆåˆ©èƒ½åŠ›: {(fundamental_signal or {}).get('reasoning', {}).get('profitability_signal', {}).get('details', 'æ— æ•°æ®')}
   - å¢é•¿æƒ…å†µ: {(fundamental_signal or {}).get('reasoning', {}).get('growth_signal', {}).get('details', 'æ— æ•°æ®')}
   - è´¢åŠ¡å¥åº·: {(fundamental_signal or {}).get('reasoning', {}).get('financial_health_signal', {}).get('details', 'æ— æ•°æ®')}
   - ä¼°å€¼æ°´å¹³: {(fundamental_signal or {}).get('reasoning', {}).get('price_ratios_signal', {}).get('details', 'æ— æ•°æ®')}

2. ä¼°å€¼åˆ†æ (æƒé‡35%):
   ä¿¡å·: {signal_to_chinese(valuation_signal)}
   ç½®ä¿¡åº¦: {((valuation_signal or {}).get('confidence', 0.0) * 100):.0f}%
   è¦ç‚¹:
   - DCFä¼°å€¼: {(valuation_signal or {}).get('reasoning', {}).get('dcf_analysis', {}).get('details', 'æ— æ•°æ®')}
   - æ‰€æœ‰è€…æ”¶ç›Šæ³•: {(valuation_signal or {}).get('reasoning', {}).get('owner_earnings_analysis', {}).get('details', 'æ— æ•°æ®')}

3. æŠ€æœ¯åˆ†æ (æƒé‡25%):
   ä¿¡å·: {signal_to_chinese(technical_signal)}
   ç½®ä¿¡åº¦: {((technical_signal or {}).get('confidence', 0.0) * 100):.0f}%
   è¦ç‚¹:
   - è¶‹åŠ¿è·Ÿè¸ª: ADX={((technical_signal or {}).get('strategy_signals', {}).get('trend_following', {}).get('metrics', {}).get('adx', 0.0)):.2f}
   - å‡å€¼å›å½’: RSI(14)={((technical_signal or {}).get('strategy_signals', {}).get('mean_reversion', {}).get('metrics', {}).get('rsi_14', 0.0)):.2f}
   - åŠ¨é‡æŒ‡æ ‡:
     * 1æœˆåŠ¨é‡={((technical_signal or {}).get('strategy_signals', {}).get('momentum', {}).get('metrics', {}).get('momentum_1m', 0.0)):.2%}
     * 3æœˆåŠ¨é‡={((technical_signal or {}).get('strategy_signals', {}).get('momentum', {}).get('metrics', {}).get('momentum_3m', 0.0)):.2%}
     * 6æœˆåŠ¨é‡={((technical_signal or {}).get('strategy_signals', {}).get('momentum', {}).get('metrics', {}).get('momentum_6m', 0.0)):.2%}
   - æ³¢åŠ¨æ€§: {((technical_signal or {}).get('strategy_signals', {}).get('volatility', {}).get('metrics', {}).get('historical_volatility', 0.0)):.2%}

4. å®è§‚åˆ†æ (ç»¼åˆæƒé‡15%):
   a) å¸¸è§„å®è§‚åˆ†æ (æ¥è‡ª Macro Analyst Agent):
      ä¿¡å·: {signal_to_chinese(general_macro_signal)}
      ç½®ä¿¡åº¦: {((general_macro_signal or {}).get('confidence', 0.0) * 100):.0f}%
      å®è§‚ç¯å¢ƒ: {(general_macro_signal or {}).get('macro_environment', 'æ— æ•°æ®')}
      å¯¹è‚¡ç¥¨å½±å“: {(general_macro_signal or {}).get('impact_on_stock', 'æ— æ•°æ®')}
      å…³é”®å› ç´ : {', '.join((general_macro_signal or {}).get('key_factors', ['æ— æ•°æ®']))}

   b) å¤§ç›˜å®è§‚æ–°é—»åˆ†æ (æ¥è‡ª Macro News Agent):
      ä¿¡å·: {signal_to_chinese(market_wide_news_signal)}
      ç½®ä¿¡åº¦: {((market_wide_news_signal or {}).get('confidence', 0.0) * 100):.0f}%
      æ‘˜è¦æˆ–ç»“è®º: {(market_wide_news_signal or {}).get('reasoning', market_wide_news_summary)}

5. æƒ…ç»ªåˆ†æ (æƒé‡10%):
   ä¿¡å·: {signal_to_chinese(sentiment_signal)}
   ç½®ä¿¡åº¦: {((sentiment_signal or {}).get('confidence', 0.0) * 100):.0f}%
   åˆ†æ: {(sentiment_signal or {}).get('reasoning', 'æ— è¯¦ç»†åˆ†æ')}

äºŒã€é£é™©è¯„ä¼°
é£é™©è¯„åˆ†: {(risk_signal or {}).get('risk_score', 'æ— æ•°æ®')}/10
ä¸»è¦æŒ‡æ ‡:
- æ³¢åŠ¨ç‡: {((risk_signal or {}).get('risk_metrics', {}).get('volatility', 0.0) * 100):.1f}%
- æœ€å¤§å›æ’¤: {((risk_signal or {}).get('risk_metrics', {}).get('max_drawdown', 0.0) * 100):.1f}%
- VaR(95%): {((risk_signal or {}).get('risk_metrics', {}).get('value_at_risk_95', 0.0) * 100):.1f}%
- å¸‚åœºé£é™©: {(risk_signal or {}).get('risk_metrics', {}).get('market_risk_score', 'æ— æ•°æ®')}/10

ä¸‰ã€æŠ•èµ„å»ºè®®
æ“ä½œå»ºè®®: {'ä¹°å…¥' if action == 'buy' else 'å–å‡º' if action == 'sell' else 'æŒæœ‰'}
äº¤æ˜“æ•°é‡: {quantity}è‚¡
å†³ç­–ç½®ä¿¡åº¦: {confidence*100:.0f}%

å››ã€å†³ç­–ä¾æ®
{reasoning}

===================================="""

    return {
        "action": action,
        "quantity": quantity,
        "confidence": confidence,
        "agent_signals": agent_signals,
        "åˆ†ææŠ¥å‘Š": detailed_analysis
    }
